Title : ............
Abstract
Background: Automatic analysis of chest X-rays using deep learning represents a major advancement in medical artificial intelligence. However, model quality crucially depends on methodological data preparation. Objective: This study presents a comprehensive analysis of the NIH ChestX-ray14 dataset and establishes a rigorous preparation pipeline for deep learning model training. Methods: We analyzed 112,120 chest radiographs from 30,805 patients, focusing on data cleaning, exploratory analysis, and technical preparation. Results: 
……………….
Keywords: Chest X-ray, NIH ChestX-ray14, Multi-label Classification, Medical Imaging, Data Preprocessing, Computer-Aided Diagnosis, Deep Learning, Healthcare AI

1. Introduction
Chest imaging represents one of the most frequently performed radiological examinations worldwide, with over 2 billion annual exams according to the World Health Organization. Facing this growing demand, diagnostic automation through artificial intelligence represents a promising solution to improve healthcare efficiency and accessibility.
The NIH ChestX-ray14 dataset, developed by the US National Institutes of Health, represents one of the largest collections of annotated chest radiographs available for research. With 112,120 images from 30,805 patients, it offers a unique opportunity for the development and validation of automatic pulmonary pathology detection algorithms.
However, the inherent complexity of medical data - including technical variations, pathology diversity, and annotation specificities - requires a rigorous methodological approach before implementing any deep learning models. This article details the crucial data preparation phase, an often underestimated but essential step for the success of AI applications in medical imaging.
2. Methodology
2.1. Metadata Loading and AnalysisDataset 
•	shape: 112,120 entries × 12 columns
•	Core columns analyzed: Image Index, Finding Labels, Patient ID, Patient Age, Patient Gender, View Position
•	Multi-label analysis: Exploded label lists for comprehensive pathology distribution
•	Patient statistics: Unique patient count and image distribution patterns
2.2.  Data Quality Assessment
•	Age validation: 16 outliers identified (0.014% of dataset)
•	Gender normalization: Standardized to uppercase ['M', 'F'] format
•	Label cleaning: Whitespace removal and string normalization
•	Missing value analysis: Comprehensive null value assessment across all columns
2.3.  Data Cleaning 

The data cleaning phase implemented a comprehensive validation framework addressing three critical dimensions:
Age Validation:
•	Outlier Detection: Systematic scan for physiologically implausible values
•	Range Filtering: Identified 16 cases (0.014%) with age <0 or >100 years
•	Medical Context: Values >100 considered improbable for standard clinical practice
•	Handling Strategy: Replacement with NaN to maintain dataset integrity while preserving record structure
•	Impact Analysis: Minimal data loss (0.014%) with significant quality improvement
Gender Normalization:
•	Format Standardization: Converted to uppercase ['M', 'F'] encoding
•	Completeness Check: 100% valid entries (112,120/112,120)
•	Consistency Validation: No ambiguous or missing gender designations
•	Encoding Scheme: Binary encoding compatible with ML preprocessing pipelines
Label Processing:
•	String Cleaning: Removal of leading/trailing whitespaces from image filenames and diagnostic labels
•	Format Harmonization: Standardized label formatting across all entries
•	Character Encoding: Ensured UTF-8 compatibility for international character sets
•	Multi-label Integrity: Preserved pipe-separated label structure during cleaning operations
3. Comprehensive Visualization Framework
The EDA employed a multi-faceted approach through a 6-plot dashboard revealing critical dataset characteristics:
3.1. Label Distribution Analysis
Figure 1 illustrates the distribution of the number of pathologies (labels) assigned to each image in the dataset (Total Images: 112,120). It is characterized by a strong asymmetry. The majority of images, specifically 91,324, contain only a single label. Images with two labels represent the second largest group with 14,306 occurrences. The number of images decreases drastically as the number of labels increases (e.g., 4,856 for three labels, 1,247 for four), and becomes very rare for eight (2 images) and nine (1 image) labels, indicating a predominance of simple or mono-pathological cases.
 
Figure 1 : Distribution of Pathology Labels per Image
3.2.  Gender Distribution:
Figure 2 shows the distribution of individuals in the dataset according to gender. The Male gender (M) is slightly predominant, representing 56.5% of the total. The Female gender (F) represents the remaining 43.5%. This slight disparity indicates that the dataset is slightly biased towards male patients. 
Figure 2 : Gender Distribution of Patients
3.3. Age Distribution Analysis
The age distribution is represented by this histogram. It follows an approximately normal trend, centered around the age of fifty, indicating that the dataset is primarily composed of adults. The maximum frequency is observed between 50 and 60 years old, with a notable concentration of patients in the adult age range (20 to 80 years). The distribution covers the entire age spectrum, including infants and the elderly, albeit in smaller proportions.
 
Figure 3 : Age Distribution of Patients
3.4. Top 15 Pathology Analysis
Figure 4 ranks the 15 most frequent diagnostic categories (pathologies) by number of occurrences. The category "No Finding" is the most represented, with a count exceeding 60,000. Among the actual pathologies, Infiltration is the most frequent (approximately 45,000 cases), closely followed by Effusion (approximately 35,000 cases) and Atelectasis (approximately 25,000 cases). Rare pathologies within this top 15 include Hernia, Pneumonia, and Fibrosis, each having fewer than 5,000 occurrences.
 
Figure 4 : Top 15 Most Frequent Pathologies
3.5. View Position Distribution
Figure 5 details the frequency of the two main radiological view positions. The PA (Postero-Anterior) view is the most dominant, with the number of images exceeding 65,000. The AP (Antero-Posterior) view is the second most frequent, with the number of images just under 45,000. This distribution is typical for chest imaging datasets, where the PA view is often preferred. 
Figure 5 : View Position Distribution (PA vs. AP)
3.6. Patient Imaging Frequency
Figure 6 illustrates the distribution of the number of available radiological images per unique patient. It exhibits an extremely strong asymmetry. The vast majority of patients (over 25,000 patients) have only a very small number of images (often one or two, as indicated by the very tall first bar). The majority of the dataset, therefore, originates from patients with limited follow-up or a single acquisition. Only a minority of patients has a large number of images (up to around 175), which is typical for cases requiring longitudinal or repeated follow-up.
 
Figure 6 : Images per Patient Distribution
4. Detailed Results 
Figure 7,  presents a collection of twelve chest X-ray images, organized in a three-row by four-column matrix. These images provide a visual sample of the dataset used, illustrating both cases considered normal (labeled "No Finding...") and various pathological manifestations. The represented radiological abnormalities include, among others, signs of Infiltration, Mass, and Nodule (row 1, column 2), Emphysema and Infiltration (row 2, column 2), Atelectasis (row 2, column 4), and a case of Pleural Effusion (row 3, column 2). Each image is topped by a text label summarizing the main diagnosis or the absence of a relevant pathology, confirming the multi-class nature and the level of complexity of the imaging data analyzed.
 
Figure 6 : Sample of radiographic images

. Conclusion
This study demonstrates the crucial importance of thorough preparatory analysis in developing AI systems for medical imaging. The detailed understanding of NIH ChestX-ray14 dataset characteristics - including its demographic complexity, heterogeneous pathology distribution, and multi-label annotation nature - provides solid foundations for developing robust and clinically relevant models.
……………………
. References
1.	Wang, X., Peng, Y., Lu, L., Lu, Z., Bagheri, M., & Summers, R. M. (2017). ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2097-2106.
2.	Rajpurkar, P., Irvin, J., Zhu, K., Yang, B., Mehta, H., Duan, T., ... & Ng, A. Y. (2017). CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning. arXiv preprint arXiv:1711.05225.
3.	Johnson, A. E., Pollard, T. J., Berkowitz, S. J., Greenbaum, N. R., Lungren, M. P., Deng, C. Y., ... & Mark, R. G. (2019). MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports. Scientific Data, 6(1), 1-8.
4.	Esteva, A., Robicquet, A., Ramsundar, B., Kuleshov, V., DePristo, M., Chou, K., ... & Dean, J. (2019). A guide to deep learning in healthcare. Nature Medicine, 25(1), 24-29.
5.	Litjens, G., Kooi, T., Bejnordi, B. E., Setio, A. A. A., Ciompi, F., Ghafoorian, M., ... & Sánchez, C. I. (2017). A survey on deep learning in medical image analysis. Medical Image Analysis, 42, 60-88.

